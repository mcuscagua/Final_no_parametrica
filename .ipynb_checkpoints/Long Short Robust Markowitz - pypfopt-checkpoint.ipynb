{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import read_data as imp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import LedoitWolf\n",
    "import pyfolio\n",
    "\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median(x):\n",
    "    aux = [0 for k in range(x.shape[0])]\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[0]):\n",
    "            aux[i] += np.linalg.norm(x.iloc[i,]-x.iloc[j,])\n",
    "    return x.iloc[aux == min(aux),].iloc[0,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 252\n",
    "\n",
    "symbols = pd.read_csv('Nemos.csv')['Nemo'].tolist()\n",
    "years = [x for x in range(2013,2019)]\n",
    "hist_data = imp.organizarTodo(symbols,years)\n",
    "\n",
    "Daily_Assets = pd.DataFrame()\n",
    "for asset,df in hist_data.items():\n",
    "    Daily_Assets[asset] = df['Close']\n",
    "    \n",
    "Daily_Log_Assets = Daily_Assets.pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Initial_Date = pd.to_datetime('2014-01-01')\n",
    "\n",
    "Rebalancing_dates = []\n",
    "curr_month = Initial_Date.month\n",
    "\n",
    "the_start = np.where(Initial_Date == Daily_Assets.index)[0].tolist()[0]\n",
    "\n",
    "for i in range((the_start+1), len(Daily_Assets.index)):\n",
    "    if Daily_Assets.index[i].month != curr_month:\n",
    "        Rebalancing_dates.append(Daily_Assets.index[i-1])\n",
    "        curr_month = Daily_Assets.index[i].month\n",
    "\n",
    "com = 0.0015\n",
    "BidAskSpread = 0.00016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-03a16cbf18ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# Margin Median\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdfaux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mLW_Cov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLedoitWolf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfaux\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcovariance_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mLW_Cov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\covariance\\shrunk_covariance_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;31m# Not calling the parent object to fit, to avoid computing the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;31m# covariance matrix (and potentially the precision)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massume_centered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "Markowitz_Returns = pd.DataFrame(index = Daily_Assets.index[Daily_Assets.index >= Initial_Date],\n",
    "                                  columns = ['Clasico', 'Mediana', 'Mediana Indicadora'], dtype = 'float')\n",
    "\n",
    "Curr_Wi = np.zeros(len(Daily_Assets.columns))\n",
    "RCurr_Wi = np.zeros(len(Daily_Assets.columns))\n",
    "R2Curr_Wi = np.zeros(len(Daily_Assets.columns))\n",
    "\n",
    "WC = pd.DataFrame(index=Daily_Assets.index[Daily_Assets.index >= Initial_Date], columns= Daily_Assets.columns)\n",
    "WR = pd.DataFrame(index=Daily_Assets.index[Daily_Assets.index >= Initial_Date], columns= Daily_Assets.columns)\n",
    "WR2 = pd.DataFrame(index=Daily_Assets.index[Daily_Assets.index >= Initial_Date], columns= Daily_Assets.columns)\n",
    "\n",
    "Memory_time_window = base\n",
    "\n",
    "for i in Daily_Assets.index[Daily_Assets.index >= Initial_Date]:\n",
    "            \n",
    "    if i in Rebalancing_dates:\n",
    "        \n",
    "        end = np.where(i == Daily_Assets.index)[0].tolist()[0]\n",
    "        ini = end - Memory_time_window\n",
    "        \n",
    "        dfaux = Daily_Assets.iloc[ini:end,:].pct_change().dropna(how=\"all\").copy()\n",
    "        \n",
    "        # Classic\n",
    "        mu = base * dfaux.mean()\n",
    "        S = base * dfaux.cov()\n",
    "\n",
    "        ef = EfficientFrontier(mu, S)#, weight_bounds=(-1, 1))\n",
    "        ef.max_sharpe()\n",
    "        Curr_Wi = np.array([x for y,x in ef.clean_weights().items()])\n",
    "        \n",
    "        # Margin Median\n",
    "        mu = base * dfaux.median()\n",
    "        LW_Cov = LedoitWolf().fit(dfaux).covariance_\n",
    "        S = base * LW_Cov\n",
    "\n",
    "        ef = EfficientFrontier(mu, S)#, weight_bounds=(-1, 1))\n",
    "        ef.max_sharpe()\n",
    "        RCurr_Wi = np.array([x for y,x in ef.clean_weights().items()])\n",
    "        \n",
    "        # Indicator Median\n",
    "        mu = base * find_median(dfaux)\n",
    "        LW_Cov = LedoitWolf().fit(dfaux).covariance_\n",
    "        S = base * LW_Cov\n",
    "\n",
    "        ef = EfficientFrontier(mu, S)#, weight_bounds=(-1, 1))\n",
    "        ef.max_sharpe()\n",
    "        R2Curr_Wi = np.array([x for y,x in ef.clean_weights().items()])\n",
    "        \n",
    "        # Saving Weights\n",
    "        \n",
    "        WC.loc[i,] = Curr_Wi\n",
    "        WR.loc[i,] = RCurr_Wi\n",
    "        WR2.loc[i,] = R2Curr_Wi\n",
    "        \n",
    "        Markowitz_Returns.loc[i, ['Clasico']] = np.dot(Daily_Log_Assets.loc[i,],Curr_Wi)*(1-com)*(1-BidAskSpread)\n",
    "        Markowitz_Returns.loc[i, ['Mediana']] = np.dot(Daily_Log_Assets.loc[i,],RCurr_Wi)*(1-com)*(1-BidAskSpread)\n",
    "        Markowitz_Returns.loc[i, ['Mediana Indicadora']] = np.dot(Daily_Log_Assets.loc[i,],R2Curr_Wi)*(1-com)*(1-BidAskSpread)\n",
    "    else:\n",
    "        Markowitz_Returns.loc[i, ['Clasico']] = np.dot(Daily_Log_Assets.loc[i,],Curr_Wi)*(1-com)*(1-BidAskSpread)\n",
    "        Markowitz_Returns.loc[i, ['Mediana']] = np.dot(Daily_Log_Assets.loc[i,],RCurr_Wi)*(1-com)*(1-BidAskSpread)\n",
    "        Markowitz_Returns.loc[i, ['Mediana Indicadora']] = np.dot(Daily_Log_Assets.loc[i,],R2Curr_Wi)*(1-com)*(1-BidAskSpread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights Behivor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for asset in symbols:\n",
    "#     plt.figure(figsize=(17,17))\n",
    "#     plt.plot(WC[asset][100:150])\n",
    "#     plt.plot(WR[asset][100:150])\n",
    "#     plt.plot(WR2[asset][100:150])\n",
    "#     plt.legend(['Classic', 'Robust', 'Robust2'])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Markowitz_Returns.to_excel('Resultados portafolios.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pyfolio.create_full_tear_sheet(Markowitz_Returns['Mediana'], benchmark_rets=Markowitz_Returns['Clasico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfolio.create_full_tear_sheet(Markowitz_Returns['Mediana Indicadora'], benchmark_rets=Markowitz_Returns['Clasico'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyfolio.create_full_tear_sheet(Markowitz_Returns['Mediana'], benchmark_rets=Markowitz_Returns['Mediana Indicadora'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
